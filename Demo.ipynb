{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVVWFIs62DQR"
   },
   "source": [
    "# Обзор способов решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtr7M6NCvulo"
   },
   "source": [
    "Самым простым и очевидным способом постановки задачи (как и многих проблем в NLP) является tokens classification. Решать задачу можно с помощью марковских моделей (HMM, CRF), рекуррентных нейронных сетей, сверточных нейронных сетей, архитектуры Transformer. В данной работе рассматривается только последняя. Конечно же, веса инициализируются весами модели с архитектурой BERT, предобученной на большом корпусе русского языка (DeepPavlov/rubert-base-cased). К эмбеддингам с последнего скрытого слоя на вход классификатору можно добавить POS - фичи, но на это не хватило времени. К тому же, в https://www.hse.ru/en/edu/vkr/296279742 показывается, что при использовании character-level информации такие фичи не нужны.\n",
    "\n",
    "Если поискать другие решения задачи, то можно найти основанное на построении синтаксического дерева. \n",
    "https://arxiv.org/pdf/1906.11298.pdf , \n",
    "https://www.researchgate.net/publication/270878718_Punctuation_Prediction_with_Transition-based_Parsing . Для применения таких методов нужно построить синтаксическое дерево. Модели для построения таких деревьев по тексту на русском языке не содержатся в пакетах nltk и spacy, однако можно найти предобученную или обучить самостоятельно. Ввиду связанных с этим дополнительных трудозатрат, такой подход не был применен в этой работе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLypHF6Z17sl"
   },
   "source": [
    "# Описание решения\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIAsqhrv2Ewy"
   },
   "source": [
    "Для обучения используется новости с сайта Lenta из корпуса \"Tayga\", раздел \"All News\" (https://tatianashavrina.github.io/taiga_site/downloads). В корпусе уже расставлена пунктуация, ее только необходимо выделить. Набор знаков ограничен теми, которую я сам считаю пунктуацией: **!,-.:;?()**. \n",
    "\n",
    "Каждый текст сначала разбивается на предложения с помощью nltk.wordpunct_tokenize. Каждый сэмпл состоит из трех предложений. Затем сэмпл разбивается на токены. Каждый токен, являющийся пунктуацией, удаляется и \"приклеивается\" в качестве класса к предыдущему непунктуационному токену. Таким образом, получается датасет для классификации токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4M1Q8Zf3-5oT"
   },
   "source": [
    "Для обучение модели на основе архитектуры Transformers используется библиотека HuggingFace Transformers. Модель строится следующим образом:\n",
    "\n",
    "\n",
    "```python\n",
    "import transformers\n",
    "from utils import PUNCT_TO_ID\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "config.num_labels = len(PUNCT_TO_ID) # Поменять количество выходов на слое классификации\n",
    "model = transformers.AutoModelForTokenClassification.from_pretrained('DeepPavlov/rubert-base-cased', config=config)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VZK8pMniBZDN"
   },
   "source": [
    "Код доступен в репозитории https://github.com/Lesha17/Punctuation.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBlOk3wQHmtd"
   },
   "source": [
    "# Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "UZ0JEIqdHp7z",
    "outputId": "fe7b2900-2683-40a7-fbcb-3d82493bf6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 21.8MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 20kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 30kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 40kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 51kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 61kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 71kB 6.0MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 81kB 6.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 92kB 6.6MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 102kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 112kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 122kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 133kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 143kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 153kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 163kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 174kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 184kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 194kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 204kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 215kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 225kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 235kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 245kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 256kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 266kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 276kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 286kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 296kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 307kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 317kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 327kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 337kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 348kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 358kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 368kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 378kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 389kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 399kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 409kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 419kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 430kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 440kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 450kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 460kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 471kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 481kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 491kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 501kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 512kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 522kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 532kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 542kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 552kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 563kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 573kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 583kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 593kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 604kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 614kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 624kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 634kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 645kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 655kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 665kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 675kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 686kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 696kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 706kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 716kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 727kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 737kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 747kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 757kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 768kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 778kB 6.3MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 18.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 35.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 37.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=e9af8c1fa7890bd7a70bfcd1a60e308d1df46177bd7f8e38d7488a66f627a679\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "gpxucd8qHumQ",
    "outputId": "005165d3-61cb-4b7f-be02-88ae7f00c9f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Punctuation'...\n",
      "remote: Enumerating objects: 18, done.\u001b[K\n",
      "remote: Counting objects:   5% (1/18)\u001b[K\r",
      "remote: Counting objects:  11% (2/18)\u001b[K\r",
      "remote: Counting objects:  16% (3/18)\u001b[K\r",
      "remote: Counting objects:  22% (4/18)\u001b[K\r",
      "remote: Counting objects:  27% (5/18)\u001b[K\r",
      "remote: Counting objects:  33% (6/18)\u001b[K\r",
      "remote: Counting objects:  38% (7/18)\u001b[K\r",
      "remote: Counting objects:  44% (8/18)\u001b[K\r",
      "remote: Counting objects:  50% (9/18)\u001b[K\r",
      "remote: Counting objects:  55% (10/18)\u001b[K\r",
      "remote: Counting objects:  61% (11/18)\u001b[K\r",
      "remote: Counting objects:  66% (12/18)\u001b[K\r",
      "remote: Counting objects:  72% (13/18)\u001b[K\r",
      "remote: Counting objects:  77% (14/18)\u001b[K\r",
      "remote: Counting objects:  83% (15/18)\u001b[K\r",
      "remote: Counting objects:  88% (16/18)\u001b[K\r",
      "remote: Counting objects:  94% (17/18)\u001b[K\r",
      "remote: Counting objects: 100% (18/18)\u001b[K\r",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects:   8% (1/12)\u001b[K\r",
      "remote: Compressing objects:  16% (2/12)\u001b[K\r",
      "remote: Compressing objects:  25% (3/12)\u001b[K\r",
      "remote: Compressing objects:  33% (4/12)\u001b[K\r",
      "remote: Compressing objects:  41% (5/12)\u001b[K\r",
      "remote: Compressing objects:  50% (6/12)\u001b[K\r",
      "remote: Compressing objects:  58% (7/12)\u001b[K\r",
      "remote: Compressing objects:  66% (8/12)\u001b[K\r",
      "remote: Compressing objects:  75% (9/12)\u001b[K\r",
      "remote: Compressing objects:  83% (10/12)\u001b[K\r",
      "remote: Compressing objects:  91% (11/12)\u001b[K\r",
      "remote: Compressing objects: 100% (12/12)\u001b[K\r",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 18 (delta 5), reused 17 (delta 4), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (18/18), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Lesha17/Punctuation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVzAJatcHxKV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘Lenta’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir Lenta\n",
    "!unzip -q Punctuation/data/Lenta_split.zip -d Lenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "injE_61ui_U4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  model.zip\n",
      "  inflating: model/config.json       \n",
      "  inflating: model/pytorch_model.bin  \n"
     ]
    }
   ],
   "source": [
    "!unzip model.zip -d model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYA0ogndH0Us"
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyrfuziYH1EB"
   },
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForTokenClassification.from_pretrained('model').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213,
     "referenced_widgets": [
      "7b45b49037a3443faa54747a2df2f02b",
      "facd4fcf8a7a49b09174b0223751a00a",
      "4f28d146aca543e584555e54909d00f5",
      "e1b8b230c56041dd93cf9d408dbe5635",
      "268f249b28f0480f85892998b37feae7",
      "e4989ffcab424dbb9690096c2f45b9e9",
      "6f7f97b9935c43f38eaeba4e2f4f7a98",
      "ad5df427e21e4bcaaf39493c6007d9a5",
      "457909b202504beeae6ae6f6ff5c8f3c",
      "3d7bd20a6ea741dd9a872506c1e1e199",
      "971da80c62b441f4b4de4c6249519a70",
      "a5cc313677904f1ea26fddd633be1142",
      "ad666825a9de4f619d7d1d1087ab4b4f",
      "b55ba16bede1471aa7331c4fb072934d",
      "aeeb69ddd0f841be935fa0619b6b6deb",
      "d0d95e219cdc4a149ecda056f390fd47",
      "15a0eccea63842188b9031cd442dcd13",
      "db7c933ca2674152a010e4b5e7da703c",
      "a92174a58f91408fad23fe3dbd4cbdf0",
      "12d220f6c86e42bd8abf2ad10804e835",
      "144fd40b24ed4b6899f2a77e97be7fc8",
      "43e2158c18fd46d18b03dad5a8c296be",
      "d6777fbde7ec422ba1ae1fe722cab775",
      "93da7db11fc64872ba45c6089cbb88c8",
      "4e273d5f339f4eadb10b056fc816b213",
      "d56a18ca07144f249393f3940e1952a5",
      "7745c19305414159ac5b0552b3e6d68a",
      "722a108cc0fd434c9287166ff19849ca",
      "6d53c30196684511a4a2ccdf01b1f2ee",
      "13a775b8a0b244339158860568bf9f62",
      "1bde1ef3dd444ec7a6306630682c683b",
      "a63712f6a89e4857954a4763c97720d4"
     ]
    },
    "colab_type": "code",
    "id": "_VcBKwBdH1KE",
    "outputId": "b4d87326-bb3c-4ee7-d2b5-4d5cc417dbe7"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NZZMrhzoIBz-",
    "outputId": "4fc31781-63cd-4d2b-c4b7-389d478b3b8d"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOW_j1iOH1Ol"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Punctuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXVRJ2nZH1RY"
   },
   "outputs": [],
   "source": [
    "from data_reader import PunctuationDataset\n",
    "from utils import PUNCT_TO_ID\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAtR5Q14IFUa"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "def read(dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=transformers.default_data_collator)\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    outputs = []\n",
    "    mask = []\n",
    "    for batch in tqdm.autonotebook.tqdm(dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch = {k: t.to('cuda') for k, t in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model(**batch)\n",
    "        true_labels.append(batch['labels'].cpu())\n",
    "        outputs.append(model_outputs[1].cpu())\n",
    "        mask.append(batch['attention_mask'].cpu())\n",
    "\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    outputs = np.concatenate(outputs, axis=0)\n",
    "    mask = np.concatenate(mask, axis=0)\n",
    "\n",
    "    outputs = outputs.reshape(-1, 10)\n",
    "    true_labels = true_labels.reshape(-1)\n",
    "    mask = mask.reshape(-1)\n",
    "    outputs = outputs[mask != 0]\n",
    "    true_labels = true_labels[mask != 0]\n",
    "    \n",
    "    return outputs, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTA9wcWTJWDN"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def custom_acc(y_true, y_pred):\n",
    "    interest_idx = np.logical_or(y_pred != 0, y_true != 0)\n",
    "    return accuracy_score(y_true[interest_idx], y_pred[interest_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5vLiWYqH1WZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caclulating length of dataset Lenta/dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29242b847f584051b22266d388f2c835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_dev = PunctuationDataset(data_dir='Lenta/dev', tokenizer=tokenizer, label_to_idx=PUNCT_TO_ID, batch_size=BATCH_SIZE)\n",
    "dev_outputs, dev_true_labels = read(dataset_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajeLIwIEiyWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caclulating length of dataset Lenta/test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601312fd253448e28e71972af69f91b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_test = PunctuationDataset(data_dir='Lenta/test', tokenizer=tokenizer, label_to_idx=PUNCT_TO_ID, batch_size=BATCH_SIZE)\n",
    "test_outputs, test_true_labels = read(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqhKSwGvJTev"
   },
   "outputs": [],
   "source": [
    "dev_labels_predict = np.argmax(dev_outputs, axis=-1)\n",
    "test_labels_predict = np.argmax(test_outputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByKfL2rnJYYs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8976816089587333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_acc(dev_true_labels, dev_labels_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895375187248638"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_acc(test_true_labels, test_labels_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWDJs0bZjxGR"
   },
   "source": [
    "И теперь применяем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xzw6NQ1vj0U2"
   },
   "outputs": [],
   "source": [
    "from utils import PUNCTUATION, PUNCT_TO_ID\n",
    "\n",
    "def restore_punct(token_ids, tokenizer, token_label_ids):\n",
    "    result = ''\n",
    "    for token_id, label_id in list(zip(token_ids, token_label_ids)):\n",
    "        token_id = token_id.item()\n",
    "        if token_id == tokenizer.cls_token_id:\n",
    "            continue\n",
    "        if token_id in (tokenizer.sep_token_id, tokenizer.pad_token_id):\n",
    "            break\n",
    "        token = tokenizer.ids_to_tokens[token_id]\n",
    "        if token.startswith('##'):\n",
    "            result = result[:-2] # remove last added punctuation\n",
    "            token = token[2:]\n",
    "        elif len(result) > 0 and result[-1] != ' ':\n",
    "            result += ' '\n",
    "            \n",
    "        result += token\n",
    "        result += ' ' + (' ' + PUNCTUATION)[label_id]\n",
    "    return result\n",
    "\n",
    "def make_punct(texts, model, tokenizer):\n",
    "    encoded = tokenizer(texts, max_length=192, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "    encoded = {k: v.cuda() for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        model_out = model(**encoded)\n",
    "    predicted_tokens = torch.argmax(model_out[0], dim=-1)\n",
    "    results = []\n",
    "    for sample_ids, sample_predicts in list(zip(encoded['input_ids'], predicted_tokens)):\n",
    "        result = restore_punct(sample_ids, tokenizer, sample_predicts)\n",
    "\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3kGuojoj1Ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['начиная  жизнеописание  героя  моего , алексея  федоровича , карамазова  нахожусь  в  некотором  недоуменииа . именно  хотя  я  и  называю  алексея  федоровича  моим  героем , но  однако  сам  знаю , что  человек  он  отнюдь  не  великии , а  посему  и  предвижу  неизбежные  вопросы  вроде  таковых . чем  же  замечателен  ваш  алексеи  федорович , что  вы  выбрали  его  своим  героем ?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_punct([\"Начиная жизнеописание героя моего Алексея Федоровича Карамазова нахожусь в некотором недоумении\" \\\n",
    "           \"А именно хотя я и называю Алексея Федоровича моим героем но однако сам знаю что человек он \" \\\n",
    "           \"отнюдь не великий а посему и предвижу неизбежные вопросы вроде таковых чем же замечателен ваш \" \\\n",
    "           \"Алексей Федорович что вы выбрали его своим героем\"], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "def check_one(reference, hypothesis):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    ref = wordpunct_tokenize(reference)\n",
    "    hyp = wordpunct_tokenize(hypothesis)\n",
    "    ref_i, hyp_i = 0, 0\n",
    "    punct_places = 0\n",
    "    while ref_i < len(ref) and hyp_i < len(hyp):\n",
    "        need_punct_check_ref = False\n",
    "        need_punct_check_hyp = False\n",
    "        cur_ref = ref[ref_i]\n",
    "        if cur_ref in PUNCT_TO_ID:\n",
    "            need_punct_check_ref = True\n",
    "            punct_places += 1\n",
    "        cur_hyp = hyp[hyp_i]\n",
    "        if cur_hyp in PUNCT_TO_ID:\n",
    "            need_punct_check_hyp = True\n",
    "        if need_punct_check_ref and need_punct_check_hyp:\n",
    "            if cur_ref == cur_hyp:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "            ref_i += 1\n",
    "            hyp_i += 1\n",
    "            continue\n",
    "\n",
    "        if need_punct_check_ref and not need_punct_check_hyp:\n",
    "            incorrect += 1\n",
    "            ref_i += 1\n",
    "            continue\n",
    "\n",
    "        if not need_punct_check_ref and need_punct_check_hyp:\n",
    "            incorrect += 1\n",
    "            hyp_i += 1\n",
    "            continue\n",
    "\n",
    "        assert cur_hyp == cur_ref, \"The phrases are inconsistent!\" + cur_hyp + ' ' + cur_ref\n",
    "        ref_i += 1\n",
    "        hyp_i += 1\n",
    "    if punct_places == 0:\n",
    "        return 1 - incorrect/(2 * len(reference))\n",
    "        \n",
    "    return correct/punct_places - incorrect/(2 * len(reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(s, keep_punct=True):\n",
    "    encoded = tokenizer(s, max_length=192, truncation=True, add_special_tokens=False)\n",
    "    result = ''\n",
    "    for idx in encoded.input_ids:\n",
    "        token = tokenizer.ids_to_tokens[idx]\n",
    "        if keep_punct or token not in PUNCT_TO_ID:\n",
    "            result += token + ' '\n",
    "    return result.replace(' ##', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, wordpunct_tokenize\n",
    "import os\n",
    "\n",
    "def eval_data(data_dir, sentences_per_sample=3):\n",
    "    results = []\n",
    "    for filename in tqdm.autonotebook.tqdm(os.listdir(data_dir)):\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            file_samples = []\n",
    "            file_samples_no_punct = []\n",
    "            with open(filepath) as file:\n",
    "                sentences = sent_tokenize(file.read())\n",
    "                for i in range(len(sentences) - sentences_per_sample):\n",
    "                    sample = ' '.join(sentences[i:i + sentences_per_sample])\n",
    "                            \n",
    "                    file_samples.append(prepare(sample))\n",
    "                    file_samples_no_punct.append(prepare(sample, keep_punct=False))\n",
    "            if len(file_samples) > 0:\n",
    "                file_samples_predict = make_punct(file_samples_no_punct, model, tokenizer)\n",
    "                for sample, sample_pred in zip(file_samples, file_samples_predict):\n",
    "                    try:\n",
    "                        results.append(check_one(sample, sample_pred))\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29570eb2a56f4460919cada8dc5e7007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9095.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = eval_data('Lenta/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8851497053424776\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.average(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь попробуем евалить, не учитывая, что после слова может быть больше 1 знака пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset(dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, collate_fn=transformers.default_data_collator)\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for batch in tqdm.autonotebook.tqdm(dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch = {k: t.to('cuda') for k, t in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model(**batch)\n",
    "            \n",
    "        labels_true = batch['labels'].cpu()\n",
    "        labels_predict = torch.argmax(model_outputs[1], dim=-1).cpu()\n",
    "        \n",
    "        for sample_ids, sample_true_labels, sample_predict_labels in list(zip(batch['input_ids'].cpu(), labels_true, labels_predict)):\n",
    "            sample = restore_punct(sample_ids, tokenizer, sample_true_labels)\n",
    "            sample_pred = restore_punct(sample_ids, tokenizer, sample_predict_labels)\n",
    "            \n",
    "            try:\n",
    "                results.append(check_one(sample, sample_pred))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0c4fbaa64b44cda9a448d0e05925e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = eval_dataset(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202121713530056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.average(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HuaweiPunctuationTask.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12d220f6c86e42bd8abf2ad10804e835": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93da7db11fc64872ba45c6089cbb88c8",
      "placeholder": "​",
      "style": "IPY_MODEL_d6777fbde7ec422ba1ae1fe722cab775",
      "value": " 112/112 [00:01&lt;00:00, 79.1B/s]"
     }
    },
    "13a775b8a0b244339158860568bf9f62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "144fd40b24ed4b6899f2a77e97be7fc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "15a0eccea63842188b9031cd442dcd13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a92174a58f91408fad23fe3dbd4cbdf0",
       "IPY_MODEL_12d220f6c86e42bd8abf2ad10804e835"
      ],
      "layout": "IPY_MODEL_db7c933ca2674152a010e4b5e7da703c"
     }
    },
    "1bde1ef3dd444ec7a6306630682c683b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "268f249b28f0480f85892998b37feae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3d7bd20a6ea741dd9a872506c1e1e199": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43e2158c18fd46d18b03dad5a8c296be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "457909b202504beeae6ae6f6ff5c8f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_971da80c62b441f4b4de4c6249519a70",
       "IPY_MODEL_a5cc313677904f1ea26fddd633be1142"
      ],
      "layout": "IPY_MODEL_3d7bd20a6ea741dd9a872506c1e1e199"
     }
    },
    "4e273d5f339f4eadb10b056fc816b213": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7745c19305414159ac5b0552b3e6d68a",
       "IPY_MODEL_722a108cc0fd434c9287166ff19849ca"
      ],
      "layout": "IPY_MODEL_d56a18ca07144f249393f3940e1952a5"
     }
    },
    "4f28d146aca543e584555e54909d00f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4989ffcab424dbb9690096c2f45b9e9",
      "max": 642,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_268f249b28f0480f85892998b37feae7",
      "value": 642
     }
    },
    "6d53c30196684511a4a2ccdf01b1f2ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6f7f97b9935c43f38eaeba4e2f4f7a98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "722a108cc0fd434c9287166ff19849ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a63712f6a89e4857954a4763c97720d4",
      "placeholder": "​",
      "style": "IPY_MODEL_1bde1ef3dd444ec7a6306630682c683b",
      "value": " 2.00/2.00 [00:00&lt;00:00, 3.34B/s]"
     }
    },
    "7745c19305414159ac5b0552b3e6d68a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13a775b8a0b244339158860568bf9f62",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d53c30196684511a4a2ccdf01b1f2ee",
      "value": 2
     }
    },
    "7b45b49037a3443faa54747a2df2f02b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f28d146aca543e584555e54909d00f5",
       "IPY_MODEL_e1b8b230c56041dd93cf9d408dbe5635"
      ],
      "layout": "IPY_MODEL_facd4fcf8a7a49b09174b0223751a00a"
     }
    },
    "93da7db11fc64872ba45c6089cbb88c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971da80c62b441f4b4de4c6249519a70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b55ba16bede1471aa7331c4fb072934d",
      "max": 1649718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad666825a9de4f619d7d1d1087ab4b4f",
      "value": 1649718
     }
    },
    "a5cc313677904f1ea26fddd633be1142": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0d95e219cdc4a149ecda056f390fd47",
      "placeholder": "​",
      "style": "IPY_MODEL_aeeb69ddd0f841be935fa0619b6b6deb",
      "value": " 1.65M/1.65M [00:01&lt;00:00, 931kB/s]"
     }
    },
    "a63712f6a89e4857954a4763c97720d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a92174a58f91408fad23fe3dbd4cbdf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43e2158c18fd46d18b03dad5a8c296be",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_144fd40b24ed4b6899f2a77e97be7fc8",
      "value": 112
     }
    },
    "ad5df427e21e4bcaaf39493c6007d9a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad666825a9de4f619d7d1d1087ab4b4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "aeeb69ddd0f841be935fa0619b6b6deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b55ba16bede1471aa7331c4fb072934d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0d95e219cdc4a149ecda056f390fd47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d56a18ca07144f249393f3940e1952a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6777fbde7ec422ba1ae1fe722cab775": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db7c933ca2674152a010e4b5e7da703c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1b8b230c56041dd93cf9d408dbe5635": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad5df427e21e4bcaaf39493c6007d9a5",
      "placeholder": "​",
      "style": "IPY_MODEL_6f7f97b9935c43f38eaeba4e2f4f7a98",
      "value": " 642/642 [00:04&lt;00:00, 160B/s]"
     }
    },
    "e4989ffcab424dbb9690096c2f45b9e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "facd4fcf8a7a49b09174b0223751a00a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
